#!/usr/bin/env python3
"""
RSã‚·ã‚¹ãƒ†ãƒ 2024å¹´åº¦CSVæ­£è¦åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å‰æ: data/download/RS_2024/ ã«æ‰‹å‹•ã§ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿

å‡¦ç†ãƒ•ãƒ­ãƒ¼:
1. data/download/RS_2024/ å†…ã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£å‡
2. è§£å‡ã—ãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ­£è¦åŒ–
   - neologdnã«ã‚ˆã‚‹æ­£è¦åŒ–ï¼ˆæœ€å„ªå…ˆï¼‰
   - ä¸¸æ•°å­—ã®å¤‰æ›
   - Unicode NFKCæ­£è¦åŒ–
   - å’Œæš¦â†’è¥¿æš¦å¤‰æ›
   - å…¨è§’æ‹¬å¼§â†’åŠè§’æ‹¬å¼§å¤‰æ›
   - ãƒã‚¤ãƒ•ãƒ³ãƒ»é•·éŸ³ã®ä¿®æ­£
   - é€£ç¶šç©ºç™½ã®å‰Šé™¤
3. æ­£è¦åŒ–ã—ãŸCSVã‚’ data/year_2024/ ã¸å‡ºåŠ›
4. data/download/RS_2024/ å†…ã®ZIPä»¥å¤–ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
"""

import os
import sys
import csv
import re
import unicodedata
import zipfile
from pathlib import Path
from typing import List

# neologdnã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import neologdn
    NEOLOGDN_AVAILABLE = True
except ImportError:
    print('âš ï¸  neologdn ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“')
    print('   pip3 install neologdn ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„')
    NEOLOGDN_AVAILABLE = False

INPUT_DIR = Path(__file__).parent.parent / 'data' / 'download' / 'RS_2024'
OUTPUT_DIR = Path(__file__).parent.parent / 'data' / 'year_2024'

# å’Œæš¦â†’è¥¿æš¦å¤‰æ›ãƒãƒƒãƒ—
ERA_TO_YEAR = {
    'ä»¤å’Œ': 2018,
    'å¹³æˆ': 1988,
    'æ˜­å’Œ': 1925,
}

def convert_circled_numbers(text: str) -> str:
    """ä¸¸æ•°å­—ã‚’é€šå¸¸æ•°å­—ã«å¤‰æ›"""
    circled = 'â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©â‘ªâ‘«â‘¬â‘­â‘®â‘¯â‘°â‘±â‘²â‘³'
    for i, char in enumerate(circled, 1):
        text = text.replace(char, str(i))
    return text

def convert_era_to_year(text: str) -> str:
    """å’Œæš¦ã‚’è¥¿æš¦ã«å¤‰æ›"""
    for era, base_year in ERA_TO_YEAR.items():
        pattern = f'{era}(\\d+)å¹´'
        matches = re.finditer(pattern, text)
        for match in matches:
            era_year = int(match.group(1))
            western_year = base_year + era_year
            text = text.replace(match.group(0), f'{western_year}å¹´')
    return text

def convert_fullwidth_brackets(text: str) -> str:
    """å…¨è§’æ‹¬å¼§ã‚’åŠè§’æ‹¬å¼§ã«å¤‰æ›"""
    text = text.replace('ï¼ˆ', '(')
    text = text.replace('ï¼‰', ')')
    return text

def fix_hyphen_to_choon(text: str) -> str:
    """ãƒã‚¤ãƒ•ãƒ³â†’é•·éŸ³ã®èª¤ç”¨ä¿®æ­£"""
    text = re.sub(r'([ã‚¡-ãƒ´])-', r'\1ãƒ¼', text)
    return text

def unify_hyphens(text: str) -> str:
    """ãƒã‚¤ãƒ•ãƒ³ãƒ»ãƒ€ãƒƒã‚·ãƒ¥ã‚’çµ±ä¸€"""
    text = text.replace('âˆ’', '-')
    text = text.replace('ï¼', '-')
    text = text.replace('â€', '-')
    text = text.replace('â€“', '-')
    text = text.replace('â€”', '-')
    text = text.replace('â€•', '-')
    return text

def fix_katakana_choon(text: str) -> str:
    """ã‚«ã‚¿ã‚«ãƒŠé•·éŸ³è¨˜å·ã®èª¤ç”¨ä¿®æ­£"""
    text = re.sub(r'([ã‚¡-ãƒ´])ãƒ¼+', r'\1ãƒ¼', text)
    return text

def remove_consecutive_spaces(text: str) -> str:
    """é€£ç¶šç©ºç™½ã‚’1ã¤ã«å‰Šé™¤"""
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def normalize_text(text: str) -> str:
    """ãƒ†ã‚­ã‚¹ãƒˆã®æ­£è¦åŒ–å‡¦ç†ï¼ˆãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼‰"""
    if not text:
        return text

    # 1. neologdnã«ã‚ˆã‚‹æ­£è¦åŒ–ï¼ˆæœ€å„ªå…ˆï¼‰
    if NEOLOGDN_AVAILABLE:
        text = neologdn.normalize(text)

    # 2. ä¸¸æ•°å­—ã®å¤‰æ›
    text = convert_circled_numbers(text)

    # 3. Unicode NFKCæ­£è¦åŒ–
    text = unicodedata.normalize('NFKC', text)

    # 4. å’Œæš¦â†’è¥¿æš¦å¤‰æ›
    text = convert_era_to_year(text)

    # 5. å…¨è§’æ‹¬å¼§â†’åŠè§’æ‹¬å¼§
    text = convert_fullwidth_brackets(text)

    # 6. ãƒã‚¤ãƒ•ãƒ³â†’é•·éŸ³ã®ä¿®æ­£ï¼ˆNFKCå¾Œã«å®Ÿè¡Œï¼‰
    text = fix_hyphen_to_choon(text)

    # 7. ãƒã‚¤ãƒ•ãƒ³ãƒ»ãƒ€ãƒƒã‚·ãƒ¥ã®çµ±ä¸€
    text = unify_hyphens(text)

    # 8. ã‚«ã‚¿ã‚«ãƒŠé•·éŸ³è¨˜å·ã®èª¤ç”¨ä¿®æ­£
    text = fix_katakana_choon(text)

    # 9. é€£ç¶šç©ºç™½ã®å‰Šé™¤
    text = remove_consecutive_spaces(text)

    return text

def extract_all_zips(directory: Path) -> List[Path]:
    """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ã™ã¹ã¦ã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£å‡"""
    zip_files = list(directory.glob('*.zip'))
    extracted_files = []

    if not zip_files:
        print('âš ï¸  ZIPãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
        return extracted_files

    print(f'ã€ZIPè§£å‡ã€‘ {len(zip_files)}å€‹ã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£å‡ä¸­...')
    print('-' * 60)

    for zip_path in zip_files:
        try:
            print(f'ğŸ“¦ è§£å‡ä¸­: {zip_path.name}')
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(directory)
                extracted_files.extend([directory / name for name in zip_ref.namelist()])
            print(f'   âœ… å®Œäº†')
        except Exception as e:
            print(f'   âŒ ã‚¨ãƒ©ãƒ¼: {e}')

    print(f'\nè§£å‡å®Œäº†: {len(extracted_files)}ãƒ•ã‚¡ã‚¤ãƒ«\n')
    return extracted_files

def normalize_csv_file(input_path: Path, output_dir: Path) -> bool:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ­£è¦åŒ–"""
    try:
        print(f'ğŸ”§ æ­£è¦åŒ–ä¸­: {input_path.name}')

        # UTF-8ã§èª­ã¿è¾¼ã¿ï¼ˆBOMå¯¾å¿œï¼‰
        with open(input_path, 'r', encoding='utf-8-sig') as f:
            reader = csv.reader(f)
            rows = list(reader)

        # å„ã‚»ãƒ«ã‚’æ­£è¦åŒ–
        normalized_rows = []
        for row in rows:
            normalized_row = [normalize_text(cell) for cell in row]
            normalized_rows.append(normalized_row)

        # UTF-8ã§æ›¸ãè¾¼ã¿ï¼ˆBOMãªã—ï¼‰
        output_path = output_dir / input_path.name
        with open(output_path, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerows(normalized_rows)

        print(f'   âœ… å‡ºåŠ›: {output_path.name}')
        return True

    except Exception as e:
        print(f'   âŒ ã‚¨ãƒ©ãƒ¼: {e}')
        return False

def cleanup_non_zip_files(directory: Path):
    """ZIPä»¥å¤–ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
    print('ã€ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã€‘ ZIPä»¥å¤–ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ä¸­...')
    print('-' * 60)

    deleted_count = 0
    for item in directory.iterdir():
        if item.is_file() and item.suffix.lower() != '.zip':
            try:
                print(f'ğŸ—‘ï¸  å‰Šé™¤: {item.name}')
                item.unlink()
                deleted_count += 1
            except Exception as e:
                print(f'   âŒ å‰Šé™¤å¤±æ•—: {e}')

    print(f'\nã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {deleted_count}ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤\n')

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print('=' * 60)
    print('RSã‚·ã‚¹ãƒ†ãƒ 2024å¹´åº¦ CSV æ­£è¦åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ')
    print('=' * 60)

    if not NEOLOGDN_AVAILABLE:
        print('\nâš ï¸  neologdn ãªã—ã§ç¶šè¡Œã—ã¾ã™ï¼ˆæ­£è¦åŒ–å“è³ªãŒä½ä¸‹ã—ã¾ã™ï¼‰')
        response = input('ç¶šè¡Œã—ã¾ã™ã‹? (y/N): ')
        if response.lower() != 'y':
            print('ä¸­æ­¢ã—ã¾ã—ãŸ')
            sys.exit(1)

    # å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒã‚§ãƒƒã‚¯
    if not INPUT_DIR.exists():
        print(f'âŒ å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {INPUT_DIR}')
        print(f'   {INPUT_DIR} ã‚’ä½œæˆã—ã¦ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã—ã¦ãã ã•ã„')
        sys.exit(1)

    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    print(f'\nå…¥åŠ›å…ƒ: {INPUT_DIR}')
    print(f'å‡ºåŠ›å…ˆ: {OUTPUT_DIR}\n')

    # Phase 1: ZIPè§£å‡
    extracted_files = extract_all_zips(INPUT_DIR)

    if not extracted_files:
        print('âŒ è§£å‡ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“')
        sys.exit(1)

    # Phase 2: CSVæ­£è¦åŒ–
    csv_files = [f for f in INPUT_DIR.glob('*.csv')]

    if not csv_files:
        print('âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
        sys.exit(1)

    print(f'ã€CSVæ­£è¦åŒ–ã€‘ {len(csv_files)}å€‹ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ­£è¦åŒ–ä¸­...')
    print('-' * 60)

    success_count = 0
    for csv_path in csv_files:
        if normalize_csv_file(csv_path, OUTPUT_DIR):
            success_count += 1

    print(f'\næ­£è¦åŒ–å®Œäº†: {success_count}/{len(csv_files)} ãƒ•ã‚¡ã‚¤ãƒ«\n')

    # Phase 3: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    cleanup_non_zip_files(INPUT_DIR)

    print('=' * 60)
    print('ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼')
    print(f'æ­£è¦åŒ–ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«: {OUTPUT_DIR}')
    print('=' * 60)

if __name__ == '__main__':
    main()
